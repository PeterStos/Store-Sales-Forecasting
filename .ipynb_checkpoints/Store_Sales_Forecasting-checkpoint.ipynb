{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0639406d",
   "metadata": {},
   "source": [
    " ## Data Field Information\n",
    "\n",
    "### train.csv\n",
    "- The training data, comprising time series of features store_nbr, family, and onpromotion as well as the target sales.\n",
    "- store_nbr identifies the store at which the products are sold.\n",
    "- family identifies the type of product sold.\n",
    "- sales gives the total sales for a product family at a particular store at a given date. Fractional values are possible since products can be sold in fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\n",
    "- onpromotion gives the total number of items in a product family that were being promoted at a store at a given date.\n",
    "\n",
    "### test.csv\n",
    "- The test data, having the same features as the training data. You will predict the target sales for the dates in this file.\n",
    "- The dates in the test data are for the 15 days after the last date in the training data.\n",
    "\n",
    "### stores.csv\n",
    "- Store metadata, including city, state, type, and cluster.\n",
    "- cluster is a grouping of similar stores.\n",
    "\n",
    "### oil.csv\n",
    "- Daily oil price. Includes values during both the train and test data timeframes. (Ecuador is an oil-dependent country and it's economical health is highly vulnerable to shocks in oil prices.)\n",
    "\n",
    "### holidays_events.csv\n",
    "- Holidays and Events, with metadata\n",
    "- NOTE - Transferred column: A holiday that is transferred officially falls on that calendar day, but was moved to another date by the government. A transferred day is more like a normal day than a holiday. To find the day that it was actually celebrated, look for the corresponding row where type is Transfer. For example, the holiday Independencia de Guayaquil was transferred from 2012-10-09 to 2012-10-12, which means it was celebrated on 2012-10-12. Days that are type Bridge are extra days that are added to a holiday (e.g., to extend the break across a long weekend). These are frequently made up by the type Work Day which is a day not normally scheduled for work (e.g., Saturday) that is meant to payback the Bridge.\n",
    "- Additional holidays are days added a regular calendar holiday, for example, as typically happens around Christmas (making Christmas Eve a holiday).\n",
    "\n",
    "## Additional Notes\n",
    "- Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.\n",
    "- A magnitude 7.8 earthquake struck Ecuador on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4414c6",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9de16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries for time series forecasting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Time series analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Utility\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Custom function for RMSLE (competition metric)\n",
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"Root Mean Squared Logarithmic Error\"\"\"\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d73b1",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d11456e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path and name\n",
    "train_path = './data/train.csv'\n",
    "test_path = './data/test.csv'\n",
    "transactions_path = './data/transactions.csv'\n",
    "oil_path = './data/oil.csv'\n",
    "holidays_events_path = './data/holidays_events.csv'\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "transactions_df = pd.read_csv(transactions_path)\n",
    "oil_df = pd.read_csv(oil_path)\n",
    "holidays_events_df = pd.read_csv(holidays_events_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2165a4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "Train: (3000888, 6)\n",
      "Test: (28512, 5)\n",
      "Transactions: (83488, 3)\n",
      "Oil: (1218, 2)\n",
      "Holidays/Events: (350, 6)\n"
     ]
    }
   ],
   "source": [
    "# Quick overview of all datasets\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Train: {train_df.shape}\")\n",
    "print(f\"Test: {test_df.shape}\")\n",
    "print(f\"Transactions: {transactions_df.shape}\")\n",
    "print(f\"Oil: {oil_df.shape}\")\n",
    "print(f\"Holidays/Events: {holidays_events_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e18eae3",
   "metadata": {},
   "source": [
    "### Utility Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2719c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print main information about a dataset\n",
    "def ds_info(df):\n",
    "    print(colored('SIZE' , 'blue', attrs=['bold', 'dark']))\n",
    "    print(df.size)\n",
    "    print(colored('\\nSHAPE' , 'blue', attrs=['bold', 'dark']))\n",
    "    print(df.shape)\n",
    "    print(colored('\\nINFO' , 'blue', attrs=['bold', 'dark']))\n",
    "    print(df.info())\n",
    "    print(colored('\\nNULL VALUES' , 'blue', attrs=['bold', 'dark']))\n",
    "    print(df.isnull().sum())\n",
    "    print(colored('\\nHEAD' , 'blue', attrs=['bold', 'dark']))\n",
    "    print(df.head())\n",
    "    print(colored('\\nTAIL' , 'blue', attrs=['bold', 'dark']))\n",
    "    print(df.tail())\n",
    "    print(colored('\\nDESCRIBE - Numerical' , 'blue', attrs=['bold', 'dark']))\n",
    "    print(df.describe())\n",
    "    print(colored('\\nDESCRIBE - Categorical' , 'blue', attrs=['bold', 'dark']))\n",
    "    print(df.describe(include='object'))\n",
    "    \n",
    "    print(colored('\\nUNIQUE ENTRIES IN EACH NUMERICAL COLUMN' , 'blue', attrs=['bold', 'dark']))\n",
    "    # Get number of unique entries in each column with numerical data\n",
    "    num_cols = [col for col in df.columns if df[col].dtype != \"object\"]\n",
    "    num_nunique = list(map(lambda col: df[col].nunique(), num_cols))    \n",
    "    dn = dict(zip(num_cols, num_nunique))\n",
    "    # Print number of unique entries by column, in ascending order\n",
    "    print(sorted(dn.items(), key=lambda x: x[1]))\n",
    "    \n",
    "    print(colored('\\nUNIQUE ENTRIES IN EACH CATEGORICAL COLUMN' , 'blue', attrs=['bold', 'dark']))\n",
    "    # Get number of unique entries in each column with categorical data\n",
    "    object_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    object_nunique = list(map(lambda col: df[col].nunique(), object_cols))\n",
    "    dc = dict(zip(object_cols, object_nunique))\n",
    "    # Print number of unique entries by column, in ascending order\n",
    "    print(sorted(dc.items(), key=lambda x: x[1]))\n",
    "    \n",
    "    \n",
    "# Function to parse date \n",
    "def parse_datetime(data):\n",
    "    #convert date.datetime to type datetime \n",
    "    data.datetime = pd.to_datetime(data.datetime)\n",
    "    # split in columns\n",
    "    data['year'] = data['datetime'].dt.year\n",
    "    data['month'] = data['datetime'].dt.month\n",
    "    data['day'] = data['datetime'].dt.day\n",
    "    data['hour'] = data['datetime'].dt.hour\n",
    "    data['weekday'] = data['datetime'].dt.weekday\n",
    "    \n",
    "    \n",
    "# Function to detect and print outliers \n",
    "def detect_outliers(data):\n",
    "    # mean, standard deviation and 3-sigma of the data\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    threesigma = 3 * std\n",
    "    \n",
    "    # print upper, lower boundary and boxplot\n",
    "    sns.boxplot(data, orient=\"v\")\n",
    "    plt.show()\n",
    "    lower, upper = mean-3*std, mean+3*std\n",
    "    print(f\"Upper and lower boundary is: {lower}/{upper}\")\n",
    "    \n",
    "    # identify outliers and return the outliers\n",
    "    outliers = [x for x in data if np.abs(x - mean) > threesigma]\n",
    "    print(f\"There are {len(outliers)} outliers based on three-sigma rule\")\n",
    "\n",
    "    \n",
    "# Function to delete the outliers \n",
    "def delete_outliers(data, df):\n",
    "    \"\"\" Detecting and dropping outliers \"\"\"\n",
    "    original_shape = df.shape\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    outliers = np.abs(data-mean) > (3*std)\n",
    "    outliers_num = len(train[outliers])\n",
    "    df.drop(index=data[outliers].index, inplace=True)\n",
    "    \n",
    "    # print what was deleted\n",
    "    print(\"Number of outliers deleted:\", outliers_num)\n",
    "    print (\"Shape of dataframe with Ouliers: \",original_shape)\n",
    "    print (\"Shape of Dataframe After Deleting the Ouliers: \",df.shape)\n",
    "\n",
    "    \n",
    "# Function to plot the Correlation Heatmap\n",
    "def correlation_heatmap(corr):\n",
    "    \"\"\" Correlation Heatmap \"\"\"\n",
    "    mask = np.array(corr)\n",
    "    mask[np.tril_indices_from(mask)] = False\n",
    "    \n",
    "    # plot the correlation\n",
    "    fig,ax= plt.subplots()\n",
    "    fig.set_size_inches(10,10)\n",
    "    sns.heatmap(corr, mask=mask,vmax=.8, square=True,annot=True)\n",
    "\n",
    "# Function to calculate RMSLE - Root Mean Squared Logarithmic Error   \n",
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\" Custom RMSLE scorer function.\"\"\"\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))\n",
    "    \n",
    "\n",
    "def check_date_columns(df):\n",
    "    \"\"\"Identify and analyze date columns\"\"\"\n",
    "    date_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                pd.to_datetime(df[col].head(100))\n",
    "                date_cols.append(col)\n",
    "            except:\n",
    "                pass\n",
    "    print(colored('POTENTIAL DATE COLUMNS:', 'yellow', attrs=['bold']))\n",
    "    print(date_cols)\n",
    "    return date_cols\n",
    "\n",
    "\n",
    "def missing_data_summary(df):\n",
    "    \"\"\"Enhanced missing data analysis\"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = 100 * missing / len(df)\n",
    "    missing_table = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Missing %': missing_pct\n",
    "    }).sort_values('Missing %', ascending=False)\n",
    "    return missing_table[missing_table['Missing Count'] > 0]\n",
    "\n",
    "\n",
    "def plot_time_series(df, date_col, value_col, title=\"Time Series\"):\n",
    "    \"\"\"Quick time series plot\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(pd.to_datetime(df[date_col]), df[value_col])\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a4c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d325319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab850f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7d7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b7bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e5bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
